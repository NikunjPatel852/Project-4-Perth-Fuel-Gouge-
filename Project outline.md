Project 4 Perth Fuel Gouge 
The University of Western Australia Data Analytics Final Project 
By Nikunj Patel 

Project Requirements 
    •	Use ML: Skikit-Learn and/or another machine learning library 
    •	Use at least 2 of the following: Python Pandas, Python Matplotlib, HTML/CDD/Bootstrap, JavaScript Plotly, JavaScript D3.js, JavaScript Leaflet, Sql Database, MongoDb Database, Google Cloud Sql, Amazon AWS, Tableau.  
    •	Host application using a tool of your choice. 

Project Overview 
    To create a webpage that displays historical and daily changes in fuel prices across Western Australia. The general audience this web page is intended for is the public who may be interested in finding out the cost of fuel in Perth. The web page will provide different types of charts that examine changes in prices over the last 24 months to view trends such as: 
        •	Fuel prices North vs South of the river. 
        •	Prices comparison between Metro and Regional 
        •	Best price brand for fuel 
        •	Comparing different types of fuels and average prices. 
        •	Comparing daily prices to find best day to fuel up. 
        •	Plotting a map that lays out pricing for each fuel station. 
    Machine Learning 
        •	Explore different models to predict the price of fuel in Western Australia. 
    (Need to add more after some research) 

Project Breakdown 
    The following is a simple break down of tasks to give a general overview on how the schedule for this project was broken down. The time frame for this project was two weeks starting from 11th to 25th of November 2021. 
    11th to 13th of November – Draft and framework. 
        1.	Create a draft outline of the webpage viewing examples online grabbing ideas and finalizing the number of visuals and interactive items on the webpage. 
        2.	Start crabbing the data from fuel watch webpage. As the files are broken down into monthly csv’s best find a way to join them together. Draft a database schema that supports the chosen visuals. Deploy a database. 
        3.	Use Tableau to start building some of the suggested visuals to get an idea. 
        4.	Also make a copy of the data for the machine learning component (requires research on best format)

14th to 17th of November – Complete web page and storytelling 
    1.	Do some research on free web page’s layouts that can be used find one that fits the draft design. 
    2.	Test run a simple JavaScript Plotly graph with a flask app to see if a recreation of the graphs works. If not use tableau. 
    3.	Draft out all the text to explain each graph ensure spelling and grammar. 
    4.	Build a home page that outlines purpose and provides a interactive map for users. 
    5.	Build a storytelling page that outlines all the trends found. 

18th to 20st of November – Machine Learning Models 
    1.	Look at different models that have been used to do such prediction before as examples.
    2.	Pick two different types to see with is more efficient. 
    3.	Outline findings on webpage. 
    
21st to 22nd of November – Move product to AWS for hosting. 


 

